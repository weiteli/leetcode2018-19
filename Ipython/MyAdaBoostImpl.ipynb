{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Reference:\n",
    "1. https://adataanalyst.com/machine-learning/adaboost-python-3/\n",
    "2. https://www.python-course.eu/Boosting.php\n",
    "3. https://cole-maclean.github.io/blog/Adaboost-Predicting-Churn/\n",
    "4. https://github.com/eriklindernoren/ML-From-Scratch/blob/master/mlfromscratch/supervised_learning/adaboost.py\n",
    "5. https://medium.com/@chih.sheng.huang821/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-ensemble-learning%E4%B9%8Bbagging-boosting%E5%92%8Cadaboost-af031229ebc3\n",
    "6. https://www.youtube.com/watch?v=tH9FH1DH5n0\n",
    "'''\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data = datasets.load_digits()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "digit1 = 1\n",
    "digit2 = 8\n",
    "idx = np.append(np.where(y == digit1)[0], np.where(y == digit2)[0])\n",
    "y = data.target[idx]\n",
    "# Change labels to {-1, 1}\n",
    "y[y == digit1] = -1\n",
    "y[y == digit2] = 1\n",
    "X = data.data[idx]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class DecisionStump():\n",
    "    def __init__(self):\n",
    "        self.polarity = 1\n",
    "        self.feature_dim = None\n",
    "        self.threshold = None\n",
    "        self.alpha = None\n",
    "\n",
    "class MyAdaboost():\n",
    "    def __init__(self, n_classifier):\n",
    "        self.n_classifier= n_classifier\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_dim = np.shape(X)\n",
    "        weight = np.ones(n_samples)/n_samples\n",
    "        self.classifiers = []\n",
    "        \n",
    "        for _ in range(self.n_classifier):\n",
    "            # Decision Stump is a decision tree with depth 1\n",
    "            classifier = DecisionStump()\n",
    "            \n",
    "            # Find random dimension for \n",
    "            # random.seed(random.random())\n",
    "            # d = random.randint(0, n_dim-1)\n",
    "            # using random dimension for classifier result is not good\n",
    "            min_error = float('inf')\n",
    "            for d in range(n_dim):\n",
    "                unique_vals = set(X[:, d])\n",
    "                for thres in unique_vals:\n",
    "                    p = 1\n",
    "                    predictions = np.ones(n_samples)\n",
    "                    predictions[X[:, d] < thres] = -1\n",
    "                    error = sum(weight[y!=predictions])\n",
    "                    if error > 0.5:\n",
    "                        error = 1-error\n",
    "                        p = -1\n",
    "\n",
    "                    if error < min_error:\n",
    "                        min_error = error\n",
    "                        classifier.polarity = p\n",
    "                        classifier.threshold = thres\n",
    "                        classifier.feature_dim = d\n",
    "                        \n",
    "            classifier.alpha = 0.5*np.log((1-min_error)/(min_error+1e-10))\n",
    "            print(\"Minimum Error {}, Alpha {}\".format(min_error, classifier.alpha))\n",
    "            predictions = np.ones(n_samples)\n",
    "            wrong_preds = (classifier.polarity * X[:, classifier.feature_dim] < classifier.polarity * classifier.threshold)\n",
    "            predictions[wrong_preds] = -1\n",
    "            weight = weight * np.exp(-classifier.alpha*y*predictions)\n",
    "            weight = weight / np.sum(weight)\n",
    "            \n",
    "            self.classifiers.append(classifier)\n",
    "            \n",
    "        \n",
    "    def predict(self, X):\n",
    "        n_samples, _ = X.shape\n",
    "        sum_predictions = np.zeros(n_samples)\n",
    "        \n",
    "        for classifier in self.classifiers:\n",
    "            pred = np.ones(n_samples)\n",
    "            wrong_preds = (classifier.polarity * X[:, classifier.feature_dim] < classifier.polarity * classifier.threshold)\n",
    "            pred[wrong_preds==True] = -1\n",
    "            sum_predictions = sum_predictions + classifier.alpha*pred\n",
    "            \n",
    "        \n",
    "        sum_predictions = np.sign(sum_predictions)\n",
    "        return sum_predictions\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Error 0.16901408450704325, Alpha 0.7963153967630227\n",
      "Minimum Error 0.18294701986318807, Alpha 0.7482536686991507\n",
      "Minimum Error 0.1508113203689272, Alpha 0.8641259384669009\n",
      "Minimum Error 0.2032580524603338, Alpha 0.6830272399883083\n",
      "Minimum Error 0.20410360060316576, Alpha 0.6804206571722484\n",
      "Minimum Error 0.21122395525854742, Alpha 0.658781731595795\n",
      "Minimum Error 0.12631090385213894, Alpha 0.9669891138814865\n",
      "Minimum Error 0.23339702137891738, Alpha 0.5946140400539544\n",
      "Minimum Error 0.2699123520880072, Alpha 0.4975336538982501\n",
      "Minimum Error 0.2609749480726081, Alpha 0.5204537007185551\n",
      "Minimum Error 0.26248465785084, Alpha 0.5165471282448121\n",
      "Minimum Error 0.27239337534646135, Alpha 0.4912566483185151\n",
      "Minimum Error 0.27082202447721226, Alpha 0.4952279847375006\n",
      "Minimum Error 0.270967241152971, Alpha 0.49486036755070123\n",
      "Minimum Error 0.2655170851693572, Alpha 0.5087437722413432\n",
      "Minimum Error 0.2803278924513035, Alpha 0.47141786962083587\n",
      "Minimum Error 0.274836918316292, Alpha 0.48510933599761524\n",
      "Minimum Error 0.2817374110992813, Alpha 0.46792987685857473\n",
      "Minimum Error 0.20888310250935332, Alpha 0.6658354817285522\n",
      "Minimum Error 0.2743491027341177, Alpha 0.4863338240331676\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Adaboost classification with 5 weak classifiers\n",
    "\n",
    "clf = MyAdaboost(20)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "count = 0\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] == y_test[i]:\n",
    "        count += 1\n",
    "\n",
    "accuracy = count / len(y_pred)        \n",
    "print (\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.59263079 1.47097947 1.53696734 1.28559835 1.30838849 1.14555895\n",
      " 0.9459087  1.10738491 0.76739656 1.32938437 0.94785876 0.54436414\n",
      " 0.75950441 0.84790799 0.87500963 1.00451105 0.70949051 0.82946359\n",
      " 0.57939936 0.65517751 1.00476565 0.72773119 0.83652    0.78600597\n",
      " 0.59929934 0.69675216 0.47656019 0.59679759 0.63984881 1.00663187]\n",
      "Accuracy: 0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),algorithm=\"SAMME\",n_estimators=30)\n",
    "bdt.fit(X_train, y_train)\n",
    "print(bdt.estimator_weights_)\n",
    "z = bdt.predict(X_test)\n",
    "count = 0\n",
    "for i in range(len(z)):\n",
    "    if z[i] == y_test[i]:\n",
    "        count += 1\n",
    "\n",
    "accuracy = count / len(y_pred)        \n",
    "print (\"Accuracy:\", accuracy) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
