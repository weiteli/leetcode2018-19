{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWkAAAFkCAYAAADi5cqQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngTFIExEJjEGaiEhg/x/vk8OGBX9lxQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10436ab38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "Reference\n",
    "1. https://github.com/random-forests/tutorials/blob/master/decision_tree.ipynb\n",
    "2. https://www.youtube.com/watch?v=7VeUPuFGJHk\n",
    "3. http://mropengate.blogspot.com/2015/06/ai-ch13-2-decision-tree.html\n",
    "4. https://medium.com/@NorthBei/machine-learning-decision-tree-764d1fab0200\n",
    "5. https://medium.com/@yehjames/%E8%B3%87%E6%96%99%E5%88%86%E6%9E%90-%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E7%AC%AC3-5%E8%AC%9B-%E6%B1%BA%E7%AD%96%E6%A8%B9-decision-tree-%E4%BB%A5%E5%8F%8A%E9%9A%A8%E6%A9%9F%E6%A3%AE%E6%9E%97-random-forest-%E4%BB%8B%E7%B4%B9-7079b0ddfbda\n",
    "'''\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, 1:3]\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "colors = ['r','g', 'b']\n",
    "label = [0, 1, 2]\n",
    "for i in range(len(y_train)):\n",
    "    ax.scatter(X_train[i][0], X_train[i][1], c=colors[y_train[i]], s=50)\n",
    "for i in range(len(y_test)):\n",
    "    ax.scatter(X_test[i][0], X_test[i][1], c=colors[y_test[i]], marker='^',s=50)\n",
    "    \n",
    "\n",
    "ax.axis('equal')\n",
    "ax.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MyDecisionNode():\n",
    "    def __init__(self, feature_dim=None, threshold=None, value=None, true_branch=None, false_branch=None):\n",
    "        self.feature_dim = feature_dim\n",
    "        self.threshold = threshold\n",
    "        self.value = value\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class MyDecisionTree():\n",
    "    def __init__(self, min_sample=2, min_info_gain=1e-7, max_depth=float('inf'), loss = None):\n",
    "        self.root = None\n",
    "        self.min_sample = min_sample\n",
    "        self.min_info_gain = min_info_gain\n",
    "        self.max_depth = max_depth\n",
    "        self.loss = loss\n",
    "    \n",
    "    def divideFeatureInTwo(self, feature, thres):\n",
    "        c1, c2 = [], []\n",
    "        for i, f in enumerate(feature):\n",
    "            if f >= thres:\n",
    "                c1.append(i)\n",
    "            else:\n",
    "                c2.append(i)\n",
    "        return c1, c2\n",
    "\n",
    "    def calculateGiniImpurity(self, c):\n",
    "        n_samples = len(c)\n",
    "        counts = Counter(c)\n",
    "        impurity = 1\n",
    "        for item in counts:\n",
    "            prob = counts[item] / n_samples\n",
    "            impurity -= prob*prob\n",
    "        return impurity\n",
    "    \n",
    "    def calculateInformationGain(self, c1, c2, y):\n",
    "        p = len(c1)/len(y)\n",
    "        prev = self.calculateGiniImpurity(y)\n",
    "        info_gain = prev - p*self.calculateGiniImpurity(y[c1]) - (1-p)*self.calculateGiniImpurity(y[c2])\n",
    "        return info_gain\n",
    "    \n",
    "    def build_decision_tree(self, X, y, depth):\n",
    "        # Called Recursively\n",
    "        n_sample, n_feature = X.shape\n",
    "        #cur_impurity = self.calculateGiniImpurity(y)\n",
    "        #min_impurity = cur_impurity\n",
    "        max_info_gain = 0\n",
    "        data_separation = dict.fromkeys(['false_X', 'false_y', 'true_X', 'true_y', 'feature_dim', 'thres', 'impurity'])\n",
    "        \n",
    "        if n_sample > self.min_sample and depth <= self.max_depth:\n",
    "            for i in range(n_feature):\n",
    "                feature_dim = X[:, i]\n",
    "                unique_val = set(feature_dim)\n",
    "                for thres in sorted(unique_val):\n",
    "                    c1, c2 = self.divideFeatureInTwo(feature_dim, thres)\n",
    "                    if len(c1) > 0 and len(c2)>0:\n",
    "                        info_gain = self.calculateInformationGain(c1,c2,y)\n",
    "                        #c1_impurity = self.calculateGiniImpurity(y[c1])\n",
    "                        #c2_impurity = self.calculateGiniImpurity(y[c2])\n",
    "                        #total_impurity = float(len(c1)/n_sample) * c1_impurity +float((len(c2)/n_sample)) * c2_impurity\n",
    "                        if info_gain > max_info_gain:\n",
    "                            max_info_gain = info_gain\n",
    "\n",
    "                        #if total_impurity < min_impurity:\n",
    "                            #min_impurity = total_impurity\n",
    "                            #print(\"C1 number: {}, C1 impurity: {}\".format(len(c1), c1_impurity)) \n",
    "                            #print(\"C2 number: {}, C2 impurity: {}\".format(len(c2), c2_impurity))\n",
    "                            # Prep for data separation\n",
    "                            #data_separation['impurity'] = min_impurity\n",
    "                            data_separation['true_X'] = X[c1, :]\n",
    "                            data_separation['true_y'] = y[c1]\n",
    "                            data_separation['false_X'] = X[c2, :]\n",
    "                            data_separation['false_y'] = y[c2]\n",
    "                            data_separation['feature_dim'] = i\n",
    "                            data_separation['thres'] = thres\n",
    "        \n",
    "        if max_info_gain > self.min_info_gain:                \n",
    "        #if cur_impurity - min_impurity > 0.01:\n",
    "        #if min_impurity < cur_impurity:\n",
    "            #print(\"Cur: {}, Min: {}\".format(cur_impurity, min_impurity))\n",
    "            #print(data_separation['feature_dim'], data_separation['thres'], data_separation['impurity'])\n",
    "            if False:\n",
    "                fig = plt.figure(figsize=(10,5))\n",
    "                ax2 = fig.add_subplot(1,2,1)\n",
    "                colors = ['r','g','b']\n",
    "                for i in range(len(data_separation['false_y'])):\n",
    "                    ax2.scatter(data_separation['false_X'][i][0], data_separation['false_X'][i][1], c=colors[data_separation['false_y'][i]], s=50)\n",
    "                ax2.axis('equal')\n",
    "                ax2.grid()\n",
    "                \n",
    "                ax1 = fig.add_subplot(1,2,2)\n",
    "                colors = ['r','g', 'b']\n",
    "                for i in range(len(data_separation['true_y'])):\n",
    "                    ax1.scatter(data_separation['true_X'][i][0], data_separation['true_X'][i][1], c=colors[data_separation['true_y'][i]], s=50)\n",
    "                ax1.axis('equal')\n",
    "                ax1.grid()\n",
    "                plt.show()\n",
    "            \n",
    "            true_branch = self.build_decision_tree(data_separation['true_X'], data_separation['true_y'], depth+1)\n",
    "            false_branch = self.build_decision_tree(data_separation['false_X'], data_separation['false_y'], depth+1)\n",
    "            \n",
    "            return MyDecisionNode(feature_dim=data_separation['feature_dim'], threshold = data_separation['thres'],\\\n",
    "                                 true_branch = true_branch, false_branch = false_branch) \n",
    "        \n",
    "        #print(\"*Cur: {}, *Min: {}\".format(cur_impurity, min_impurity))\n",
    "        \n",
    "        ct = Counter(y)\n",
    "        majority_vote = float('-inf')\n",
    "        label = None\n",
    "\n",
    "        for item in ct:\n",
    "            if ct[item] > majority_vote:\n",
    "                majority_vote = ct[item]\n",
    "                label = item\n",
    "        \n",
    "        #leaf_val = self._majority_vote(y)\n",
    "        return MyDecisionNode(value=label)\n",
    "    \n",
    "    def _majority_vote(self, y):\n",
    "        most_common = None\n",
    "        max_count = 0\n",
    "        for label in np.unique(y):\n",
    "            # Count number of occurences of samples with label\n",
    "            count = len(y[y == label])\n",
    "            if count > max_count:\n",
    "                most_common = label\n",
    "                max_count = count\n",
    "        return most_common\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.root = self.build_decision_tree(X,y, 0)\n",
    "    \n",
    "    def run_sample_predict(self, x, node=None):\n",
    "        if node == None:\n",
    "            node = self.root\n",
    "        \n",
    "        if node.value != None:\n",
    "            return node.value\n",
    "        \n",
    "        value_on_feat_dim = x[node.feature_dim]\n",
    "        \n",
    "        if value_on_feat_dim >= node.threshold:\n",
    "            branch = node.true_branch\n",
    "        else:\n",
    "            branch = node.false_branch\n",
    "\n",
    "        return self.run_sample_predict(x, branch)\n",
    "   \n",
    "    def predict(self, X):\n",
    "        y_pred = [self.run_sample_predict(s) for s in X]\n",
    "        return y_pred\n",
    "    \n",
    "    def print_tree(self, tree=None, indent=\" \"):\n",
    "        \"\"\" Recursively print the decision tree \"\"\"\n",
    "        if not tree:\n",
    "            tree = self.root\n",
    "\n",
    "        # If we're at leaf => print the label\n",
    "        if tree.value is not None:\n",
    "            print (tree.value)\n",
    "        # Go deeper down the tree\n",
    "        else:\n",
    "            # Print test\n",
    "            print (\"%s:%s? \" % (tree.feature_dim, tree.threshold))\n",
    "            # Print the true scenario\n",
    "            print (\"%sT->\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.true_branch, indent + indent)\n",
    "            # Print the false scenario\n",
    "            print (\"%sF->\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.false_branch, indent + indent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyRandomForest():\n",
    "    def __init__(self, n_tree, min_sample=2, min_info_gain=1e-7, max_depth=float('inf'), loss = None):\n",
    "        self.n_tree = n_tree\n",
    "        self.min_sample = min_sample\n",
    "        self.min_info_gain = min_info_gain\n",
    "        self.max_depth = max_depth\n",
    "        self.loss = loss\n",
    "    \n",
    "        self.trees = []\n",
    "        for i in range(self.n_tree):\n",
    "            self.trees.append(MyDecisionTree(min_sample=self.min_sample, min_info_gain=self.min_info_gain, \\\n",
    "                                             max_depth=float('inf')))\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        n_sample, n_feature = X.shape\n",
    "        for tree in self.trees:\n",
    "            # Create Bootstraped dataset\n",
    "            idx = np.random.randint(n_sample, size=n_sample)\n",
    "            b_Xdata = X[idx, :]\n",
    "            b_ydata = y[idx]\n",
    "            tree.fit(b_Xdata, b_ydata)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        res = []\n",
    "        for tree in self.trees:\n",
    "            ypred = tree.predict(X)\n",
    "            res.append(ypred)\n",
    "        \n",
    "        labels = []\n",
    "        for i in range(len(res[0])):\n",
    "            tmp = []\n",
    "            for j in range(self.n_tree):\n",
    "                tmp.append(res[j][i])\n",
    "            counts = Counter(tmp)\n",
    "            labels.append(counts.most_common(1)[0][0])\n",
    "        return labels          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9111111111111111\n"
     ]
    }
   ],
   "source": [
    "myDC = MyDecisionTree()\n",
    "myDC.fit(X_train,y_train)\n",
    "y_pred = myDC.predict(X_test)\n",
    "\n",
    "count1 = 0\n",
    "for i in range(len(y_pred)):\n",
    "    if int(y_pred[i]) == int(y_test[i]):\n",
    "        count1 += 1\n",
    "\n",
    "accuracy = count1 / len(y_pred)        \n",
    "print (\"Accuracy:\", accuracy) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "myForest = MyRandomForest(10)\n",
    "myForest.fit(X_train, y_train)\n",
    "forest_y = myForest.predict(X_test)\n",
    "\n",
    "count2 = 0\n",
    "for i in range(len(forest_y)):\n",
    "    if int(forest_y[i]) == int(y_test[i]):\n",
    "        count2 += 1\n",
    "\n",
    "accuracy = count2 / len(forest_y)        \n",
    "print (\"Accuracy:\", accuracy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "t = DecisionTreeClassifier()\n",
    "t.fit(X_train, y_train)\n",
    "yp = t.predict(X_test)\n",
    "count3 = 0\n",
    "for i in range(len(yp)):\n",
    "    if yp[i] == y_test[i]:\n",
    "        count3 += 1\n",
    "\n",
    "accuracy = count3 / len(yp)        \n",
    "print (\"Accuracy:\", accuracy) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
